## 데이터 분석 (머신러닝, 딥러닝) 프로세스
- 데이터 불러오기
  + CSV, 오라클, MySQL, PostgreSQL, 클라우드 DB 연동
- 탐색적 자료 분석
  + 데이터 전처리 및 가공
- 잠정적인 컬럼의 개수를 지정해야 함.
- 머신러닝 모델(= 통계 모델링,t.test, 분산분석, 교차분석)
- 머신러닝 모델의 경우 배포(X)
  + JSP 웹 개발 시 배우게 됨
- 통계 모델링 경우, p-value 값 기준으로, 귀무가설 및 대립가설 검정
- (공통) 결과 보고서를 작성해야함
  + PPT 만들어야 함. 

## 그래프 복습
- 수치형 데이터 시각화
- 번주형 데이터 시각화
- 데이터 관계 시각화 
- matplotlib 라이브러리 방법
- seaborn 라이브러리 방법
  + 복잡한 그래프 그려야지=> matplotlib
  + 1줄 그래프 -> seaborn

### 수치형 데이터 시각화 


```python
import seaborn as sns
titanic = sns.load_dataset('titanic')
titanic.head()
```





  <div id="df-6a537552-ed22-48df-895f-bbff39f7fece">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>survived</th>
      <th>pclass</th>
      <th>sex</th>
      <th>age</th>
      <th>sibsp</th>
      <th>parch</th>
      <th>fare</th>
      <th>embarked</th>
      <th>class</th>
      <th>who</th>
      <th>adult_male</th>
      <th>deck</th>
      <th>embark_town</th>
      <th>alive</th>
      <th>alone</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>S</td>
      <td>Third</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>no</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>C</td>
      <td>First</td>
      <td>woman</td>
      <td>False</td>
      <td>C</td>
      <td>Cherbourg</td>
      <td>yes</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>S</td>
      <td>Third</td>
      <td>woman</td>
      <td>False</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>yes</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>S</td>
      <td>First</td>
      <td>woman</td>
      <td>False</td>
      <td>C</td>
      <td>Southampton</td>
      <td>yes</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>S</td>
      <td>Third</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>no</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-6a537552-ed22-48df-895f-bbff39f7fece')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-6a537552-ed22-48df-895f-bbff39f7fece button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-6a537552-ed22-48df-895f-bbff39f7fece');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
# 히스토그램
sns.histplot(data = titanic, x='age',bins=10,hue = 'alive')#bins= 간격
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe55f3d7490>




    
![png](/images/day0706/output_4_1.png)
    



```python
# 커널밀도추정 함수 그래프
# 연속형 데이터 1개만 쓸 때 사용
sns.kdeplot(data = titanic, x ='age',hue = 'alive',multiple='stack')
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe55652eb90>




    
![png](/images/day0706/output_5_1.png)
    


## 분포도
- 수치형 데이터 한 개 컬럼의 분포를 나타내는 그래프
- 정규분포인가?


```python
sns.displot(data = titanic, x='age')
```




    <seaborn.axisgrid.FacetGrid at 0x7fe561559290>




    
![png](/images/day0706/output_7_1.png)
    



```python
sns.displot(titanic, x='age', kde='True')
```




    <seaborn.axisgrid.FacetGrid at 0x7fe561417bd0>




    
![png](/images/day0706/output_8_1.png)
    


## 범주형 데이터 시각화
- x축 범주형, y축 수치 데이터
- x축 범주형, y축 범주형
  + 히트맵




```python
# 막대 그래프
sns.barplot(x='class', y='fare', data=titanic)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe5613316d0>




    
![png](/images/day0706/output_11_1.png)
    



```python
# 포인트 플롯
sns.pointplot(x='class', y='fare', data = titanic)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe5564ac750>




    
![png](/images/day0706/output_12_1.png)
    


- boxplot
- 제 1사분위: 전체 데이터 중 하위 25%
- 사분위 범위 수 (IQR) : 제 3 사분위 - 제 1사분위
- 최댓값: 제 3사분위 +(1.5 * IQR)


```python
# boxplot
sns.boxplot(x='class', y='age', data =titanic)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe561243e90>




    
![png](/images/day0706/output_14_1.png)
    



```python
# 바이올린 플롯
sns.violinplot(x='class', y='age', hue='sex',data=titanic, split = True);
```


    
![png](/images/day0706/output_15_0.png)
    


## 카운트 플롯
- 범주형 데이터의 개수 확인 할 때 사용 


```python
sns.countplot(x='class',hue='alive', data = titanic)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe561078790>




    
![png](/images/day0706/output_17_1.png)
    


## 데이터 관계 시각화
- 여러 데이터 사이의 관계도 파악 위한 그래프 


```python
# 히트맵
flights = sns.load_dataset('flights')
flights.head()
```





  <div id="df-7799d7e2-5544-4e3e-a632-07ef23100543">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>passengers</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1949</td>
      <td>Jan</td>
      <td>112</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1949</td>
      <td>Feb</td>
      <td>118</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1949</td>
      <td>Mar</td>
      <td>132</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1949</td>
      <td>Apr</td>
      <td>129</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1949</td>
      <td>May</td>
      <td>121</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-7799d7e2-5544-4e3e-a632-07ef23100543')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-7799d7e2-5544-4e3e-a632-07ef23100543 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-7799d7e2-5544-4e3e-a632-07ef23100543');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
flights['year'].value_counts()
```




    1949    12
    1950    12
    1951    12
    1952    12
    1953    12
    1954    12
    1955    12
    1956    12
    1957    12
    1958    12
    1959    12
    1960    12
    Name: year, dtype: int64




```python
flights.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 144 entries, 0 to 143
    Data columns (total 3 columns):
     #   Column      Non-Null Count  Dtype   
    ---  ------      --------------  -----   
     0   year        144 non-null    int64   
     1   month       144 non-null    category
     2   passengers  144 non-null    int64   
    dtypes: category(1), int64(2)
    memory usage: 2.9 KB
    

pivot 사용방법: 세로, 가로그리고 결과값으로 바꿀 수 있다.


```python
import pandas as pd
from pandas import Series, DataFrame

```


```python
flights_pivot=flights.pivot(index='month',columns='year',values='passengers')
flights_pivot
```





  <div id="df-637ba909-eb62-407f-8194-c6277fd1ef2e">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>year</th>
      <th>1949</th>
      <th>1950</th>
      <th>1951</th>
      <th>1952</th>
      <th>1953</th>
      <th>1954</th>
      <th>1955</th>
      <th>1956</th>
      <th>1957</th>
      <th>1958</th>
      <th>1959</th>
      <th>1960</th>
    </tr>
    <tr>
      <th>month</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Jan</th>
      <td>112</td>
      <td>115</td>
      <td>145</td>
      <td>171</td>
      <td>196</td>
      <td>204</td>
      <td>242</td>
      <td>284</td>
      <td>315</td>
      <td>340</td>
      <td>360</td>
      <td>417</td>
    </tr>
    <tr>
      <th>Feb</th>
      <td>118</td>
      <td>126</td>
      <td>150</td>
      <td>180</td>
      <td>196</td>
      <td>188</td>
      <td>233</td>
      <td>277</td>
      <td>301</td>
      <td>318</td>
      <td>342</td>
      <td>391</td>
    </tr>
    <tr>
      <th>Mar</th>
      <td>132</td>
      <td>141</td>
      <td>178</td>
      <td>193</td>
      <td>236</td>
      <td>235</td>
      <td>267</td>
      <td>317</td>
      <td>356</td>
      <td>362</td>
      <td>406</td>
      <td>419</td>
    </tr>
    <tr>
      <th>Apr</th>
      <td>129</td>
      <td>135</td>
      <td>163</td>
      <td>181</td>
      <td>235</td>
      <td>227</td>
      <td>269</td>
      <td>313</td>
      <td>348</td>
      <td>348</td>
      <td>396</td>
      <td>461</td>
    </tr>
    <tr>
      <th>May</th>
      <td>121</td>
      <td>125</td>
      <td>172</td>
      <td>183</td>
      <td>229</td>
      <td>234</td>
      <td>270</td>
      <td>318</td>
      <td>355</td>
      <td>363</td>
      <td>420</td>
      <td>472</td>
    </tr>
    <tr>
      <th>Jun</th>
      <td>135</td>
      <td>149</td>
      <td>178</td>
      <td>218</td>
      <td>243</td>
      <td>264</td>
      <td>315</td>
      <td>374</td>
      <td>422</td>
      <td>435</td>
      <td>472</td>
      <td>535</td>
    </tr>
    <tr>
      <th>Jul</th>
      <td>148</td>
      <td>170</td>
      <td>199</td>
      <td>230</td>
      <td>264</td>
      <td>302</td>
      <td>364</td>
      <td>413</td>
      <td>465</td>
      <td>491</td>
      <td>548</td>
      <td>622</td>
    </tr>
    <tr>
      <th>Aug</th>
      <td>148</td>
      <td>170</td>
      <td>199</td>
      <td>242</td>
      <td>272</td>
      <td>293</td>
      <td>347</td>
      <td>405</td>
      <td>467</td>
      <td>505</td>
      <td>559</td>
      <td>606</td>
    </tr>
    <tr>
      <th>Sep</th>
      <td>136</td>
      <td>158</td>
      <td>184</td>
      <td>209</td>
      <td>237</td>
      <td>259</td>
      <td>312</td>
      <td>355</td>
      <td>404</td>
      <td>404</td>
      <td>463</td>
      <td>508</td>
    </tr>
    <tr>
      <th>Oct</th>
      <td>119</td>
      <td>133</td>
      <td>162</td>
      <td>191</td>
      <td>211</td>
      <td>229</td>
      <td>274</td>
      <td>306</td>
      <td>347</td>
      <td>359</td>
      <td>407</td>
      <td>461</td>
    </tr>
    <tr>
      <th>Nov</th>
      <td>104</td>
      <td>114</td>
      <td>146</td>
      <td>172</td>
      <td>180</td>
      <td>203</td>
      <td>237</td>
      <td>271</td>
      <td>305</td>
      <td>310</td>
      <td>362</td>
      <td>390</td>
    </tr>
    <tr>
      <th>Dec</th>
      <td>118</td>
      <td>140</td>
      <td>166</td>
      <td>194</td>
      <td>201</td>
      <td>229</td>
      <td>278</td>
      <td>306</td>
      <td>336</td>
      <td>337</td>
      <td>405</td>
      <td>432</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-637ba909-eb62-407f-8194-c6277fd1ef2e')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-637ba909-eb62-407f-8194-c6277fd1ef2e button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-637ba909-eb62-407f-8194-c6277fd1ef2e');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
sns.heatmap(data= flights_pivot)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe56113b910>




    
![png](/images/day0706/output_25_1.png)
    


# 라인플롯



```python
sns.lineplot(x ='year', y='passengers', data=flights)
# 신뢰구간이 있다
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe561bba210>




    
![png](/images/day0706/output_27_1.png)
    



```python
# 산점도
tips = sns.load_dataset('tips')
tips.head()
```





  <div id="df-343bc603-e75e-4b65-8197-6aee49fba9f7">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total_bill</th>
      <th>tip</th>
      <th>sex</th>
      <th>smoker</th>
      <th>day</th>
      <th>time</th>
      <th>size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>16.99</td>
      <td>1.01</td>
      <td>Female</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10.34</td>
      <td>1.66</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>21.01</td>
      <td>3.50</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>23.68</td>
      <td>3.31</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>24.59</td>
      <td>3.61</td>
      <td>Female</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-343bc603-e75e-4b65-8197-6aee49fba9f7')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-343bc603-e75e-4b65-8197-6aee49fba9f7 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-343bc603-e75e-4b65-8197-6aee49fba9f7');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
# 두 개의 연속형 데이터
sns.scatterplot(x='total_bill', y='tip',hue='time',style='sex',data = tips)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe5564868d0>




    
![png](/images/day0706/output_29_1.png)
    



```python
# 회귀선
sns.regplot(x='total_bill', y='tip', data= tips)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe5563aa810>




    
![png](/images/day0706/output_30_1.png)
    


## 선형 회귀
- 선형 회귀식을 찾는 것이 중요
- $y = 3x + 4$에 근사한 데이터 50개 생성 


```python
import numpy as np 
import pandas as pd

# 시드값 고정 
np.random.seed(0)
intercept = 4 # 절편, 상수
slope = 3 # 기울기

# 변동성 주기 위해 노이즈 생성
noise = np.random.randn(50, 1)
x = 5 * np.random.rand(50, 1) # 0과 5사이의 실숫값 50개 생성
y = slope * x + intercept + noise

# 데이터 프레임 생성
data = pd.DataFrame({'X' : x[:, 0], 'Y' : y[:, 0]})
print(data)
```

               X          Y
    0   0.794848   8.148596
    1   0.551876   6.055784
    2   3.281648  14.823682
    3   0.690915   8.313637
    4   0.982912   8.816293
    5   1.843626   8.553600
    6   4.104966  17.264987
    7   0.485506   5.305162
    8   4.189725  16.465955
    9   0.480492   5.852075
    10  4.882297  18.790936
    11  2.343256  12.484042
    12  4.883805  19.412454
    13  3.024228  13.194358
    14  3.696318  15.532817
    15  0.195939   4.921491
    16  1.414035   9.736184
    17  0.600983   5.597790
    18  1.480701   8.755171
    19  0.593639   4.926820
    20  1.589916   6.216758
    21  2.071315  10.867564
    22  0.320737   5.826649
    23  3.462361  13.644917
    24  2.833007  14.768776
    25  1.326947   6.526477
    26  2.616240  11.894479
    27  0.469703   5.221924
    28  2.879732  14.171977
    29  4.646481  19.408802
    30  1.592845   8.933482
    31  3.337052  14.389318
    32  0.658989   5.089182
    33  3.581636  12.764112
    34  1.447030   7.993179
    35  0.915957   6.904219
    36  2.932565  14.027985
    37  0.100538   5.503993
    38  4.144700  16.046774
    39  0.023477   3.768129
    40  3.389083  13.118695
    41  1.350040   6.630102
    42  3.675970  13.321640
    43  4.810943  20.383604
    44  1.243766   7.221645
    45  2.880787  12.204286
    46  2.960210  11.627834
    47  2.861260  13.361269
    48  1.115408   5.732327
    49  4.763745  18.078495
    


```python

import matplotlib.pyplot as plt
fig, ax = plt.subplots()
ax.scatter(data['X'], data['Y'])
plt.show()
```


    
![png](/images/day0706/output_33_0.png)
    



```python
import seaborn as sns 
sns.scatterplot(x = 'X', y = 'Y', data = data)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe5562eef90>




    
![png](/images/day0706/output_34_1.png)
    


# 선형 회귀 모형 훈련
- 모형 생성 후, 회귀 계수 3과 y 절편 4에 근사한 값이 나와야 한다.


```python
from sklearn.linear_model import LinearRegression 
lr_model = LinearRegression() # 선형 회귀 모델 
lr_model.fit(x, y) # 모델 훈련

print('y절편:', lr_model.intercept_)
print('회귀계수:', lr_model.coef_)
```

    y절편: [4.05757639]
    회귀계수: [[3.03754061]]
    


```python
# 예측값
y_pred = lr_model.predict(x)
fig, ax = plt.subplots()
ax.scatter(x, y)
ax.plot(x, y_pred, color='green')

# slope, intercept 
label = 'slope: {}\nintercept: {}'.format(round(lr_model.coef_[0][0], 2), round(lr_model.intercept_[0], 2))
ax.text(3.5, 4, label, style ='italic', 
        fontsize = 10, color ="green")
plt.show()
```


    
![png](/images/day0706/output_37_0.png)
    


## 로지스틱 회귀



```python
import numpy as np
import matplotlib.pyplot as plt

def sigmoid(arr, scale=1):
    arr = np.asarray(arr)
    result = 1/(1 + np.exp(-arr*scale))
    return result

x = np.linspace(-6, 6)
y = sigmoid(x)

fig, ax = plt.subplots()
ax.plot(x, y)
ax.grid(which='major', axis='y', linestyle='--')
ax.axvline(x=0, color='r', linestyle='--', linewidth=1)
ax.set_ylim(0,1)
ax.set_yticks([0, 1, 0.5])
ax.text(0-0.1, 0.5, '0.5', ha='right')
ax.set_title('Sigmoid Graph')
plt.show()
```


    
![png](/images/day0706/output_39_0.png)
    



```python
# 라이브러리 불러오기
import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# 데이터 가져오기
x = np.arange(10).reshape(-1, 1)
y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])

# 모델 생성 및 학습
model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)
model.fit(x, y)
```




    LogisticRegression(C=10.0, random_state=0, solver='liblinear')



# 모형 평가



```python
p_pred = model.predict_proba(x)
print('p_pred', p_pred, sep='\n')
```

    p_pred
    [[0.97979027 0.02020973]
     [0.94958202 0.05041798]
     [0.87976149 0.12023851]
     [0.73975066 0.26024934]
     [0.52477284 0.47522716]
     [0.30020373 0.69979627]
     [0.1428487  0.8571513 ]
     [0.06080627 0.93919373]
     [0.02453462 0.97546538]
     [0.00967652 0.99032348]]
    


```python
y_pred = model.predict(x)
print('y_pred',y_pred)
```

    y_pred [0 0 0 0 0 1 1 1 1 1]
    


```python
fig, ax = plt.subplots()
ax.scatter(x, y)
ax.plot(x, p_pred[:, 1], color = 'black',  marker='o', markersize=6)
ax.plot()

ax.set_xticks(x)
ax.set_yticks(np.arange(0, 1.1, 0.1))

ax.grid(which='major', alpha=0.5)
plt.show()
```


    
![png](/images/day0706/output_44_0.png)
    



```python
conf_m = confusion_matrix(y, y_pred)
print(conf_m)
```

    [[5 0]
     [0 5]]
    


```python
cm = confusion_matrix(y, y_pred)

fig, ax = plt.subplots(figsize=(8, 8))
ax.imshow(cm, cmap = 'Pastel2')
ax.grid(False)
ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0', 'Predicted 1'))
ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0', 'Actual 1'))
ax.set_ylim(1.5, -0.5)
for i in range(2):
    for j in range(2):
        ax.text(j, i, cm[i, j], ha='center', va='center', color='black', fontsize=40)
plt.show()
```


    
![png](/images/day0706/output_46_0.png)
    


### 결정 트리
- 분류와 회귀 문제에 모두 사용 가능
### 주요 개념
- 작동 원리
  + 데이터를 가장 잘 구분하는 조건을 정함.
  + 조건을 기준으로 데이터를 두 범주로 나눔
  + 나뉜 각 범주의 데이터를 구분하는 조건을 정함
  + 각 조건을 기준으로 데이터를 두 범주로 나눔
  + 언제까지 계속 분할할지 정한 후, 최종 결정 값을 구함.
- 불순도(Impurity)
  + 한 범주 안에 서로 다른 데이터가 얼마나 섞여 있는지 나타냄
  + 흰색과 검은색이 50:50으로 섞여 있다. (불순도 최대)
  + 흰색과 검은색으로 완전 분리 되었다. (불순도 최소)
- 엔트로피(Entropy)
  + 불확실한 정도를 의미함. 0 ~ 1로 정함.
  + 흰색과 검은색이 50:50으로 섞여 있다. 엔트로피 1
  + 흰색과 검은색으로 완전 분리 되었다. 엔트로피 0
- 정보이득(Information Gain)
  + 1에서 엔트로피를 뺀 수치
  + 정보 이득을 최대화하는 방향(엔트로피를 최소화 하는 방향)으로 노드를 분할함
- 지니 불순도(Gini Impurity)
  + 지니 불순도 값이 클수록 불순도도 높고, 작을수록 불순도도 낮음. 엔트로피와 마찬가지로 지니 불순도가 낮아지는 방향으로 노드 분할함.


```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split 
import seaborn as sns 

# tips 데이터셋 
titanic = sns.load_dataset('titanic')
titanic.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 891 entries, 0 to 890
    Data columns (total 15 columns):
     #   Column       Non-Null Count  Dtype   
    ---  ------       --------------  -----   
     0   survived     891 non-null    int64   
     1   pclass       891 non-null    int64   
     2   sex          891 non-null    object  
     3   age          714 non-null    float64 
     4   sibsp        891 non-null    int64   
     5   parch        891 non-null    int64   
     6   fare         891 non-null    float64 
     7   embarked     889 non-null    object  
     8   class        891 non-null    category
     9   who          891 non-null    object  
     10  adult_male   891 non-null    bool    
     11  deck         203 non-null    category
     12  embark_town  889 non-null    object  
     13  alive        891 non-null    object  
     14  alone        891 non-null    bool    
    dtypes: bool(2), category(2), float64(2), int64(4), object(5)
    memory usage: 80.7+ KB
    

-survived의 비율을 구한다.
0: 사망자
1: 생존자



```python
titanic['survived'].value_counts()
```




    0    549
    1    342
    Name: survived, dtype: int64




```python
# 데이터 추출
X = titanic[['pclass', 'parch', 'fare']]
y = titanic['survived']

# 훈련데이터, 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.3, random_state=42)
X_train.shape, X_test.shape, y_train.shape, y_test.shape
```




    ((623, 3), (268, 3), (623,), (268,))




```python
tree_model = DecisionTreeClassifier()
tree_model.fit(X_train, y_train)

acc = tree_model.score(X_test, y_test)
print(f'모형 정확도 : {acc:.3f}') # 정확도 측정
```

    모형 정확도 : 0.675
    

#### 랜덤포레스


```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split 
import seaborn as sns 

# tips 데이터셋 
titanic = sns.load_dataset('titanic')

X = titanic[['pclass', 'parch', 'fare']]
y = titanic['survived']

# 훈련데이터, 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.3, random_state=42)

# 모델 훈련
rf_model = RandomForestClassifier(random_state=42) # 랜덤 포레스트 정의
rf_model.fit(X_train, y_train)

acc = tree_model.score(X_test, y_test)
print(f'모형 정확도 : {acc:.3f}') # 정확도 측정 ㅠ
```

    모형 정확도 : 0.675
    

## XGBoost& LightGBM
- 전통적인 머신러닝 알고리즘의 융합
  + 선형회귀 릿지 라쏘, 과적합 방지 위한 규제
  + 결정 트리의 핵심적인 알고리즘
  + 경사 하강법
  + 부스팅 기법
- 문제점: 파라미터의 개수가 매우 많음
- 왜 많이 쓸까?
  + 모델 학습 속도
  + 성능
  - 가장 좋은 모델이란, 학습 속도는 빠르면서 성능은 좋은 것(지금까지 나온 알고리즘 보다)

- Python
  + JAVA, C, C++
  + C, C++
  + 첫번째 옵션, 우리가 자체적으로 배포하자 -> Python Wrapper API|-R, 머신러닝 프레임워크 종류 다양
  + 두번째 옵션 파이썬 머신러닝 = Scikit_Learn에서 쉽게 쓸 수 있도록 개발, Scikit-Learn Wrapper APi


```python
import xgboost as xgb 
from sklearn.model_selection import train_test_split
import seaborn as sns 

# 데이터 분리
titanic = sns.load_dataset('titanic')
# titanic.info()

# X, 독립변수, y 종속변수
X = titanic[['pclass', 'parch', 'fare']]
y = titanic['survived']

# 훈련데이터, 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, 
                                                    y, 
                                                    stratify = y, 
                                                    test_size = 0.3, 
                                                    random_state=42)

X_train.shape, X_test.shape, y_train.shape, y_test.shape
```




    ((623, 3), (268, 3), (623,), (268,))



- 여기가 핵심



```python
dtrain = xgb.DMatrix(data = X_train, label = y_train)
dtest = xgb.DMatrix(data = X_test,label = y_test)

print(dtrain)
```

    <xgboost.core.DMatrix object at 0x7fe5609ac190>
    

- 머신러닝 코드 


```python
params = {
    'max_depth':3,
    'n_estimators':100,
    'eta':0.1,
    'objective':'binary:logistic'
    
}
num_rounds = 400
w_list =[(dtrain,'train'),(dtest,'test')]
xgb_ml = xgb.train(params = params,
                   dtrain=dtrain,
                   num_boost_round=400,
                   early_stopping_rounds =100,
                   evals= w_list)
```

    [0]	train-error:0.260032	test-error:0.302239
    Multiple eval metrics have been passed: 'test-error' will be used for early stopping.
    
    Will train until test-error hasn't improved in 100 rounds.
    [1]	train-error:0.260032	test-error:0.302239
    [2]	train-error:0.260032	test-error:0.302239
    [3]	train-error:0.260032	test-error:0.302239
    [4]	train-error:0.260032	test-error:0.302239
    [5]	train-error:0.260032	test-error:0.302239
    [6]	train-error:0.260032	test-error:0.302239
    [7]	train-error:0.260032	test-error:0.302239
    [8]	train-error:0.260032	test-error:0.302239
    [9]	train-error:0.260032	test-error:0.302239
    [10]	train-error:0.260032	test-error:0.302239
    [11]	train-error:0.260032	test-error:0.302239
    [12]	train-error:0.260032	test-error:0.302239
    [13]	train-error:0.247191	test-error:0.298507
    [14]	train-error:0.247191	test-error:0.298507
    [15]	train-error:0.248796	test-error:0.302239
    [16]	train-error:0.248796	test-error:0.302239
    [17]	train-error:0.248796	test-error:0.302239
    [18]	train-error:0.248796	test-error:0.302239
    [19]	train-error:0.248796	test-error:0.302239
    [20]	train-error:0.248796	test-error:0.302239
    [21]	train-error:0.248796	test-error:0.302239
    [22]	train-error:0.248796	test-error:0.302239
    [23]	train-error:0.248796	test-error:0.302239
    [24]	train-error:0.248796	test-error:0.302239
    [25]	train-error:0.248796	test-error:0.302239
    [26]	train-error:0.248796	test-error:0.302239
    [27]	train-error:0.248796	test-error:0.302239
    [28]	train-error:0.247191	test-error:0.302239
    [29]	train-error:0.247191	test-error:0.302239
    [30]	train-error:0.247191	test-error:0.302239
    [31]	train-error:0.243981	test-error:0.298507
    [32]	train-error:0.247191	test-error:0.302239
    [33]	train-error:0.243981	test-error:0.298507
    [34]	train-error:0.243981	test-error:0.298507
    [35]	train-error:0.242376	test-error:0.294776
    [36]	train-error:0.24077	test-error:0.294776
    [37]	train-error:0.24077	test-error:0.294776
    [38]	train-error:0.24077	test-error:0.294776
    [39]	train-error:0.24077	test-error:0.294776
    [40]	train-error:0.24077	test-error:0.294776
    [41]	train-error:0.24077	test-error:0.294776
    [42]	train-error:0.24077	test-error:0.294776
    [43]	train-error:0.24077	test-error:0.294776
    [44]	train-error:0.24077	test-error:0.302239
    [45]	train-error:0.24077	test-error:0.302239
    [46]	train-error:0.24077	test-error:0.302239
    [47]	train-error:0.24077	test-error:0.302239
    [48]	train-error:0.24077	test-error:0.302239
    [49]	train-error:0.24077	test-error:0.302239
    [50]	train-error:0.24077	test-error:0.302239
    [51]	train-error:0.24077	test-error:0.302239
    [52]	train-error:0.23435	test-error:0.302239
    [53]	train-error:0.23435	test-error:0.302239
    [54]	train-error:0.232745	test-error:0.298507
    [55]	train-error:0.229535	test-error:0.298507
    [56]	train-error:0.229535	test-error:0.298507
    [57]	train-error:0.229535	test-error:0.298507
    [58]	train-error:0.229535	test-error:0.298507
    [59]	train-error:0.227929	test-error:0.294776
    [60]	train-error:0.227929	test-error:0.298507
    [61]	train-error:0.227929	test-error:0.298507
    [62]	train-error:0.227929	test-error:0.298507
    [63]	train-error:0.227929	test-error:0.298507
    [64]	train-error:0.227929	test-error:0.298507
    [65]	train-error:0.227929	test-error:0.298507
    [66]	train-error:0.227929	test-error:0.298507
    [67]	train-error:0.227929	test-error:0.298507
    [68]	train-error:0.227929	test-error:0.298507
    [69]	train-error:0.227929	test-error:0.298507
    [70]	train-error:0.227929	test-error:0.298507
    [71]	train-error:0.227929	test-error:0.298507
    [72]	train-error:0.227929	test-error:0.302239
    [73]	train-error:0.227929	test-error:0.302239
    [74]	train-error:0.229535	test-error:0.30597
    [75]	train-error:0.229535	test-error:0.30597
    [76]	train-error:0.229535	test-error:0.30597
    [77]	train-error:0.229535	test-error:0.30597
    [78]	train-error:0.229535	test-error:0.30597
    [79]	train-error:0.229535	test-error:0.30597
    [80]	train-error:0.229535	test-error:0.30597
    [81]	train-error:0.229535	test-error:0.30597
    [82]	train-error:0.229535	test-error:0.30597
    [83]	train-error:0.229535	test-error:0.30597
    [84]	train-error:0.229535	test-error:0.30597
    [85]	train-error:0.229535	test-error:0.30597
    [86]	train-error:0.229535	test-error:0.30597
    [87]	train-error:0.229535	test-error:0.30597
    [88]	train-error:0.229535	test-error:0.30597
    [89]	train-error:0.229535	test-error:0.30597
    [90]	train-error:0.229535	test-error:0.30597
    [91]	train-error:0.229535	test-error:0.30597
    [92]	train-error:0.229535	test-error:0.30597
    [93]	train-error:0.229535	test-error:0.30597
    [94]	train-error:0.227929	test-error:0.313433
    [95]	train-error:0.226324	test-error:0.313433
    [96]	train-error:0.223114	test-error:0.317164
    [97]	train-error:0.223114	test-error:0.317164
    [98]	train-error:0.223114	test-error:0.317164
    [99]	train-error:0.223114	test-error:0.317164
    [100]	train-error:0.223114	test-error:0.317164
    [101]	train-error:0.223114	test-error:0.317164
    [102]	train-error:0.223114	test-error:0.317164
    [103]	train-error:0.223114	test-error:0.317164
    [104]	train-error:0.223114	test-error:0.317164
    [105]	train-error:0.223114	test-error:0.317164
    [106]	train-error:0.223114	test-error:0.317164
    [107]	train-error:0.223114	test-error:0.317164
    [108]	train-error:0.223114	test-error:0.317164
    [109]	train-error:0.223114	test-error:0.317164
    [110]	train-error:0.223114	test-error:0.317164
    [111]	train-error:0.223114	test-error:0.317164
    [112]	train-error:0.223114	test-error:0.317164
    [113]	train-error:0.223114	test-error:0.317164
    [114]	train-error:0.223114	test-error:0.317164
    [115]	train-error:0.223114	test-error:0.317164
    [116]	train-error:0.223114	test-error:0.317164
    [117]	train-error:0.223114	test-error:0.317164
    [118]	train-error:0.223114	test-error:0.317164
    [119]	train-error:0.223114	test-error:0.317164
    [120]	train-error:0.223114	test-error:0.317164
    [121]	train-error:0.223114	test-error:0.317164
    [122]	train-error:0.223114	test-error:0.317164
    [123]	train-error:0.223114	test-error:0.317164
    [124]	train-error:0.224719	test-error:0.317164
    [125]	train-error:0.224719	test-error:0.317164
    [126]	train-error:0.224719	test-error:0.317164
    [127]	train-error:0.221509	test-error:0.317164
    [128]	train-error:0.223114	test-error:0.317164
    [129]	train-error:0.219904	test-error:0.313433
    [130]	train-error:0.215088	test-error:0.313433
    [131]	train-error:0.215088	test-error:0.313433
    [132]	train-error:0.215088	test-error:0.313433
    [133]	train-error:0.215088	test-error:0.313433
    [134]	train-error:0.215088	test-error:0.313433
    [135]	train-error:0.215088	test-error:0.313433
    Stopping. Best iteration:
    [35]	train-error:0.242376	test-error:0.294776
    
    


```python
from sklearn.metrics import accuracy_score
pred_probs =xgb_ml.predict(dtest)
y_pred = [1 if x>0.5 else 0 for x in pred_probs]

accuracy_score(y_pred,y_test)
```




    0.6977611940298507




```python
#scikit-learn api 방식
```


```python
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier #API방식

# dt = DecisionTreeClassifier()
xgb_model = XGBClassifier(objective = 'binary:logistic',
                          max_depth=3,
                          learning_rate = 0.1,
                          n_estimators=100,
                          random_state = 42)

w_list = [(X_train,y_train),(X_test,y_test)]
xgb_model.fit(X_train,y_train,eval_set =w_list, eval_metric='error',verbose=True)

y_probas = xgb_model.predict_proba(X_test)
y_pred = [1 if x>0.5 else 0 for x in pred_probs]

accuracy_score(y_pred,y_test)
```

    [0]	validation_0-error:0.260032	validation_1-error:0.302239
    [1]	validation_0-error:0.260032	validation_1-error:0.302239
    [2]	validation_0-error:0.260032	validation_1-error:0.302239
    [3]	validation_0-error:0.260032	validation_1-error:0.302239
    [4]	validation_0-error:0.260032	validation_1-error:0.302239
    [5]	validation_0-error:0.260032	validation_1-error:0.302239
    [6]	validation_0-error:0.260032	validation_1-error:0.302239
    [7]	validation_0-error:0.260032	validation_1-error:0.302239
    [8]	validation_0-error:0.260032	validation_1-error:0.302239
    [9]	validation_0-error:0.260032	validation_1-error:0.302239
    [10]	validation_0-error:0.260032	validation_1-error:0.302239
    [11]	validation_0-error:0.260032	validation_1-error:0.302239
    [12]	validation_0-error:0.260032	validation_1-error:0.302239
    [13]	validation_0-error:0.247191	validation_1-error:0.298507
    [14]	validation_0-error:0.247191	validation_1-error:0.298507
    [15]	validation_0-error:0.248796	validation_1-error:0.302239
    [16]	validation_0-error:0.248796	validation_1-error:0.302239
    [17]	validation_0-error:0.248796	validation_1-error:0.302239
    [18]	validation_0-error:0.248796	validation_1-error:0.302239
    [19]	validation_0-error:0.248796	validation_1-error:0.302239
    [20]	validation_0-error:0.248796	validation_1-error:0.302239
    [21]	validation_0-error:0.248796	validation_1-error:0.302239
    [22]	validation_0-error:0.248796	validation_1-error:0.302239
    [23]	validation_0-error:0.248796	validation_1-error:0.302239
    [24]	validation_0-error:0.248796	validation_1-error:0.302239
    [25]	validation_0-error:0.248796	validation_1-error:0.302239
    [26]	validation_0-error:0.248796	validation_1-error:0.302239
    [27]	validation_0-error:0.248796	validation_1-error:0.302239
    [28]	validation_0-error:0.247191	validation_1-error:0.302239
    [29]	validation_0-error:0.247191	validation_1-error:0.302239
    [30]	validation_0-error:0.247191	validation_1-error:0.302239
    [31]	validation_0-error:0.243981	validation_1-error:0.298507
    [32]	validation_0-error:0.247191	validation_1-error:0.302239
    [33]	validation_0-error:0.243981	validation_1-error:0.298507
    [34]	validation_0-error:0.243981	validation_1-error:0.298507
    [35]	validation_0-error:0.242376	validation_1-error:0.294776
    [36]	validation_0-error:0.24077	validation_1-error:0.294776
    [37]	validation_0-error:0.24077	validation_1-error:0.294776
    [38]	validation_0-error:0.24077	validation_1-error:0.294776
    [39]	validation_0-error:0.24077	validation_1-error:0.294776
    [40]	validation_0-error:0.24077	validation_1-error:0.294776
    [41]	validation_0-error:0.24077	validation_1-error:0.294776
    [42]	validation_0-error:0.24077	validation_1-error:0.294776
    [43]	validation_0-error:0.24077	validation_1-error:0.294776
    [44]	validation_0-error:0.24077	validation_1-error:0.302239
    [45]	validation_0-error:0.24077	validation_1-error:0.302239
    [46]	validation_0-error:0.24077	validation_1-error:0.302239
    [47]	validation_0-error:0.24077	validation_1-error:0.302239
    [48]	validation_0-error:0.24077	validation_1-error:0.302239
    [49]	validation_0-error:0.24077	validation_1-error:0.302239
    [50]	validation_0-error:0.24077	validation_1-error:0.302239
    [51]	validation_0-error:0.24077	validation_1-error:0.302239
    [52]	validation_0-error:0.23435	validation_1-error:0.302239
    [53]	validation_0-error:0.23435	validation_1-error:0.302239
    [54]	validation_0-error:0.232745	validation_1-error:0.298507
    [55]	validation_0-error:0.229535	validation_1-error:0.298507
    [56]	validation_0-error:0.229535	validation_1-error:0.298507
    [57]	validation_0-error:0.229535	validation_1-error:0.298507
    [58]	validation_0-error:0.229535	validation_1-error:0.298507
    [59]	validation_0-error:0.227929	validation_1-error:0.294776
    [60]	validation_0-error:0.227929	validation_1-error:0.298507
    [61]	validation_0-error:0.227929	validation_1-error:0.298507
    [62]	validation_0-error:0.227929	validation_1-error:0.298507
    [63]	validation_0-error:0.227929	validation_1-error:0.298507
    [64]	validation_0-error:0.227929	validation_1-error:0.298507
    [65]	validation_0-error:0.227929	validation_1-error:0.298507
    [66]	validation_0-error:0.227929	validation_1-error:0.298507
    [67]	validation_0-error:0.227929	validation_1-error:0.298507
    [68]	validation_0-error:0.227929	validation_1-error:0.298507
    [69]	validation_0-error:0.227929	validation_1-error:0.298507
    [70]	validation_0-error:0.227929	validation_1-error:0.298507
    [71]	validation_0-error:0.227929	validation_1-error:0.298507
    [72]	validation_0-error:0.227929	validation_1-error:0.302239
    [73]	validation_0-error:0.227929	validation_1-error:0.302239
    [74]	validation_0-error:0.229535	validation_1-error:0.30597
    [75]	validation_0-error:0.229535	validation_1-error:0.30597
    [76]	validation_0-error:0.229535	validation_1-error:0.30597
    [77]	validation_0-error:0.229535	validation_1-error:0.30597
    [78]	validation_0-error:0.229535	validation_1-error:0.30597
    [79]	validation_0-error:0.229535	validation_1-error:0.30597
    [80]	validation_0-error:0.229535	validation_1-error:0.30597
    [81]	validation_0-error:0.229535	validation_1-error:0.30597
    [82]	validation_0-error:0.229535	validation_1-error:0.30597
    [83]	validation_0-error:0.229535	validation_1-error:0.30597
    [84]	validation_0-error:0.229535	validation_1-error:0.30597
    [85]	validation_0-error:0.229535	validation_1-error:0.30597
    [86]	validation_0-error:0.229535	validation_1-error:0.30597
    [87]	validation_0-error:0.229535	validation_1-error:0.30597
    [88]	validation_0-error:0.229535	validation_1-error:0.30597
    [89]	validation_0-error:0.229535	validation_1-error:0.30597
    [90]	validation_0-error:0.229535	validation_1-error:0.30597
    [91]	validation_0-error:0.229535	validation_1-error:0.30597
    [92]	validation_0-error:0.229535	validation_1-error:0.30597
    [93]	validation_0-error:0.229535	validation_1-error:0.30597
    [94]	validation_0-error:0.227929	validation_1-error:0.313433
    [95]	validation_0-error:0.226324	validation_1-error:0.313433
    [96]	validation_0-error:0.223114	validation_1-error:0.317164
    [97]	validation_0-error:0.223114	validation_1-error:0.317164
    [98]	validation_0-error:0.223114	validation_1-error:0.317164
    [99]	validation_0-error:0.223114	validation_1-error:0.317164
    




    0.6977611940298507



### LightGBM Python Wrapper 방식


```python
import lightgbm as lgb 
from sklearn.model_selection import train_test_split 
from sklearn.metrics import accuracy_score
import seaborn as sns 

# tips 데이터셋 
titanic = sns.load_dataset('titanic')

X = titanic[['pclass', 'parch', 'fare']]
y = titanic['survived']

# 훈련데이터, 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.3, random_state=42)

# XGBoost 코드와 유사하다. 
dtrain = lgb.Dataset(data = X_train, label = y_train)
dtest = lgb.Dataset(data = X_test, label = y_test)

params = {'max_depth':3,
          'n_estimators':100,
          'learning_rate': 0.1,
          'objective':'binary',
          'metric' : 'binary_error', 
          'num_boost_round' : 400, 
          'verbose' : 1} 

w_list = [dtrain, dtest]
lgb_ml = lgb.train(params=params, train_set = dtrain,\
                  early_stopping_rounds=100, valid_sets= w_list)

pred_probs = lgb_ml.predict(X_test)
y_pred=[1 if x > 0.5 else 0 for x in pred_probs]

# 예측 라벨과 실제 라벨 사이의 정확도 측정
accuracy_score(y_pred, y_test)
```

    /usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument
      warnings.warn("Found `{}` in params. Will use it instead of argument".format(alias))
    

    [1]	training's binary_error: 0.383628	valid_1's binary_error: 0.384328
    Training until validation scores don't improve for 100 rounds.
    [2]	training's binary_error: 0.383628	valid_1's binary_error: 0.384328
    [3]	training's binary_error: 0.354735	valid_1's binary_error: 0.369403
    [4]	training's binary_error: 0.29695	valid_1's binary_error: 0.354478
    [5]	training's binary_error: 0.272873	valid_1's binary_error: 0.33209
    [6]	training's binary_error: 0.272873	valid_1's binary_error: 0.33209
    [7]	training's binary_error: 0.269663	valid_1's binary_error: 0.317164
    [8]	training's binary_error: 0.269663	valid_1's binary_error: 0.317164
    [9]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [10]	training's binary_error: 0.269663	valid_1's binary_error: 0.309701
    [11]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [12]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [13]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [14]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [15]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [16]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [17]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [18]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [19]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [20]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [21]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [22]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [23]	training's binary_error: 0.271268	valid_1's binary_error: 0.313433
    [24]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [25]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [26]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [27]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [28]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [29]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [30]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [31]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [32]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [33]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [34]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [35]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [36]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [37]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [38]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [39]	training's binary_error: 0.248796	valid_1's binary_error: 0.309701
    [40]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [41]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [42]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [43]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [44]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [45]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [46]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [47]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [48]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [49]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [50]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [51]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [52]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [53]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [54]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [55]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [56]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [57]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [58]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [59]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [60]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [61]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [62]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [63]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [64]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [65]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [66]	training's binary_error: 0.243981	valid_1's binary_error: 0.309701
    [67]	training's binary_error: 0.23435	valid_1's binary_error: 0.309701
    [68]	training's binary_error: 0.23435	valid_1's binary_error: 0.309701
    [69]	training's binary_error: 0.23435	valid_1's binary_error: 0.309701
    [70]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [71]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [72]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [73]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [74]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [75]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [76]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [77]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [78]	training's binary_error: 0.232745	valid_1's binary_error: 0.313433
    [79]	training's binary_error: 0.232745	valid_1's binary_error: 0.313433
    [80]	training's binary_error: 0.232745	valid_1's binary_error: 0.313433
    [81]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [82]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [83]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [84]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [85]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [86]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [87]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [88]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [89]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [90]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [91]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [92]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [93]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [94]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [95]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [96]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [97]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [98]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [99]	training's binary_error: 0.221509	valid_1's binary_error: 0.317164
    [100]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [101]	training's binary_error: 0.23114	valid_1's binary_error: 0.30597
    [102]	training's binary_error: 0.23114	valid_1's binary_error: 0.30597
    [103]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [104]	training's binary_error: 0.221509	valid_1's binary_error: 0.317164
    [105]	training's binary_error: 0.221509	valid_1's binary_error: 0.317164
    [106]	training's binary_error: 0.224719	valid_1's binary_error: 0.313433
    [107]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [108]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [109]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [110]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [111]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [112]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [113]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [114]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [115]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [116]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [117]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [118]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [119]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [120]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [121]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [122]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [123]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [124]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [125]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [126]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [127]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [128]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [129]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [130]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [131]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [132]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [133]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [134]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [135]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [136]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [137]	training's binary_error: 0.219904	valid_1's binary_error: 0.309701
    [138]	training's binary_error: 0.219904	valid_1's binary_error: 0.309701
    [139]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [140]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [141]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [142]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [143]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [144]	training's binary_error: 0.221509	valid_1's binary_error: 0.320896
    [145]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [146]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [147]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [148]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [149]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [150]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [151]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [152]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [153]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [154]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [155]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [156]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [157]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [158]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [159]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [160]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [161]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [162]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [163]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [164]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [165]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [166]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [167]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [168]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [169]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [170]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [171]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [172]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [173]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [174]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [175]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [176]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [177]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [178]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [179]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [180]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [181]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [182]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [183]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [184]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [185]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [186]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [187]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [188]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [189]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [190]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [191]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [192]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [193]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [194]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [195]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [196]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [197]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [198]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [199]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [200]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [201]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    Early stopping, best iteration is:
    [101]	training's binary_error: 0.23114	valid_1's binary_error: 0.30597
    




    0.6940298507462687




```python
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score

# model 
w_list = [dtrain, dtest]
model = LGBMClassifier(objective = 'binary', 
                       metric = 'binary_error',
                       n_estimators=100, 
                       learning_rate=0.1, 
                       max_depth=3, 
                       num_boost_round = 400,
                       random_state = 32)
model.fit(X_train, 
          y_train, 
          eval_set = [(X_train, y_train), (X_test, y_test)], 
          verbose=1,
          early_stopping_rounds = 100)
y_probas = model.predict_proba(X_test) 
y_pred=[1 if x > 0.5 else 0 for x in y_probas[:, 1]] # 예측 라벨(0과 1로 예측)

# 예측 라벨과 실제 라벨 사이의 정확도 측정
accuracy_score(y_pred, y_test)
```

    [1]	training's binary_error: 0.383628	valid_1's binary_error: 0.384328
    Training until validation scores don't improve for 100 rounds.
    [2]	training's binary_error: 0.383628	valid_1's binary_error: 0.384328
    [3]	training's binary_error: 0.354735	valid_1's binary_error: 0.369403
    [4]	training's binary_error: 0.29695	valid_1's binary_error: 0.354478
    [5]	training's binary_error: 0.272873	valid_1's binary_error: 0.33209
    [6]	training's binary_error: 0.272873	valid_1's binary_error: 0.33209
    [7]	training's binary_error: 0.269663	valid_1's binary_error: 0.317164
    [8]	training's binary_error: 0.269663	valid_1's binary_error: 0.317164
    [9]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [10]	training's binary_error: 0.269663	valid_1's binary_error: 0.309701
    [11]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [12]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [13]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [14]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [15]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [16]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [17]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [18]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [19]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [20]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [21]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [22]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [23]	training's binary_error: 0.271268	valid_1's binary_error: 0.313433
    [24]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [25]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [26]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [27]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [28]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [29]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [30]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [31]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [32]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [33]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [34]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [35]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [36]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [37]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [38]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [39]	training's binary_error: 0.248796	valid_1's binary_error: 0.309701
    [40]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [41]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [42]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [43]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [44]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [45]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [46]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [47]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [48]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [49]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [50]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [51]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [52]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [53]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [54]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [55]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [56]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [57]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [58]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [59]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [60]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [61]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [62]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [63]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [64]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [65]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [66]	training's binary_error: 0.243981	valid_1's binary_error: 0.309701
    [67]	training's binary_error: 0.23435	valid_1's binary_error: 0.309701
    [68]	training's binary_error: 0.23435	valid_1's binary_error: 0.309701
    [69]	training's binary_error: 0.23435	valid_1's binary_error: 0.309701
    [70]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [71]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [72]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [73]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [74]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [75]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [76]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [77]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [78]	training's binary_error: 0.232745	valid_1's binary_error: 0.313433
    [79]	training's binary_error: 0.232745	valid_1's binary_error: 0.313433
    [80]	training's binary_error: 0.232745	valid_1's binary_error: 0.313433
    [81]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [82]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [83]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [84]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [85]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [86]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [87]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [88]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [89]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [90]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [91]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [92]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [93]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [94]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [95]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [96]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [97]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [98]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [99]	training's binary_error: 0.221509	valid_1's binary_error: 0.317164
    [100]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [101]	training's binary_error: 0.23114	valid_1's binary_error: 0.30597
    [102]	training's binary_error: 0.23114	valid_1's binary_error: 0.30597
    [103]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [104]	training's binary_error: 0.221509	valid_1's binary_error: 0.317164
    [105]	training's binary_error: 0.221509	valid_1's binary_error: 0.317164
    [106]	training's binary_error: 0.224719	valid_1's binary_error: 0.313433
    [107]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [108]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [109]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [110]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [111]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [112]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [113]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [114]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [115]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [116]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [117]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [118]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [119]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [120]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [121]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [122]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [123]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [124]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [125]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [126]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [127]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [128]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [129]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [130]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [131]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [132]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [133]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [134]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [135]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [136]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [137]	training's binary_error: 0.219904	valid_1's binary_error: 0.309701
    [138]	training's binary_error: 0.219904	valid_1's binary_error: 0.309701
    [139]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [140]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [141]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [142]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [143]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [144]	training's binary_error: 0.221509	valid_1's binary_error: 0.320896
    [145]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [146]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [147]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [148]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [149]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [150]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [151]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [152]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [153]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [154]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [155]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [156]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [157]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [158]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [159]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [160]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [161]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [162]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [163]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [164]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [165]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [166]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [167]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [168]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [169]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [170]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [171]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [172]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [173]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [174]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [175]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [176]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [177]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [178]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [179]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [180]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [181]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [182]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [183]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [184]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [185]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [186]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [187]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [188]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [189]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [190]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [191]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [192]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [193]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [194]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [195]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [196]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [197]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [198]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [199]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [200]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [201]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    Early stopping, best iteration is:
    [101]	training's binary_error: 0.23114	valid_1's binary_error: 0.30597
    

    /usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument
      warnings.warn("Found `{}` in params. Will use it instead of argument".format(alias))
    




    0.6940298507462687


